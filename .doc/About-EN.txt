Since the advent of powerful language models, reinforced by their recent breakthrough, expectations for language-based interactions between humans and machines have grown rapidly. This has also increased the need to be able to investigate the feasibility and value of such interactions. While the capabilities of language models are making fascinating progress, the ability to control these models is lagging behind. Training a language model from scratch remains unrealistic due to the resources and data required in the context of individual projects. Fine-tuning models requires time-consuming and careful preparation of training data, making fast, iterative experimentation difficult. In addition, both approaches offer insufficient options for reliably and flexibly controlling model behavior across complex interactions.

In addition to training from scratch and fine-tuning, a type of control based on prompts is currently spreading. This type is often referred to as prompt engineering and exploits the zero- and few-shot learning capability of language models. This is proving to be a valuable method for controlling language models.
However, there is a lack of support for the design and implementation of complex interactions. Progress is being made in the design of prompts in order to implement certain tasks with increasing reliability and flexibility. Further progress is being made in the possibilities of automatically enriching prompts with information. Libraries and frameworks that support the development of language model applications at the level of individual tasks are also currently emerging from this. However, there are still no models that can be used to explicitly specify complex interactions in order to support their design and implementation.

We have therefore developed a framework that supports the design and implementation of complex, language-based interactions. Based on the concepts of state machines, multi-layered interactions can be developed using language models, optimizing both the controllability and the flexibility of such models. The framework enables model-driven, dynamic prompt compositions, on the one hand along hierarchical nesting, on the other hand taking into account explicit conditions and actions that are evaluated across any interaction window.

The framework supports experimental investigations into the feasibility and usefulness of language-based interactions by providing powerful abstractions for developers and ready-to-use web applications that can be used to design, instantiate and deliver interactions to users.

Since its development, we have continuously used this framework profitably in several projects. Complex, language-based interactions such as for increasing health literacy in deaf adolescents, increasing treatment adherence in patients with chronic diseases and for promoting tax morale as a contribution to reducing administrative burdens have been successfully implemented and experimentally tested with the framework.